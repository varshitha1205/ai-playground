ğŸš€ Overview
This project is a FastAPI-based AI Assistant that integrates multiple LLM providers (Groq, OpenAI, Google Gemini) with RAG (Retrieval-Augmented Generation) using ChromaDB and HuggingFace embeddings.

It supports:
Conversational AI with persona customization
Knowledge base ingestion from files (PDF, DOCX, CSV, Excel, TXT)
SQL database querying via LangChainâ€™s SQLDatabaseChain
Real-time chat with context from vectorstore
Configurable API keys and models

âš™ï¸ Features
ğŸ”‘ Multiple LLM Providers: Groq, OpenAI, Google Gemini
ğŸ“‚ File Ingestion: Upload and process documents into ChromaDB
ğŸ—„ï¸ Database Integration: Query SQL databases with natural language
ğŸ§  RAG Support: Retrieve context from ingested documents
ğŸ¨ Chart Data Support: Special JSON output for chart rendering
ğŸ”§ Configurable Settings: API keys, persona, active model, DB settings
